chapter 3 in [xv6 book](https://pdos.csail.mit.edu/6.828/2024/xv6/book-riscv-rev4.pdf)
- each process gets own private address space and memory through this
- isolate address spaces and multiplex them onto a single physical mem
- level of indirection that allows tricks
- in xv6, tricks are:
	- mapping same memory in several address spaces (trampoline page)
	- guarding kernel and user stacks with unmapped page
# paging hardware
- RISC-V instructions manipulate virtual addresses
- machine's RAM has physical addresses
- page tables are a translation mechanism
- only bottom 39 bits of 64-bit virtual address used in Sv39
- each page table is an array of $2^{27}$ page table entries
	- 27-bit address needed to create a row index, and to locate a specific entry
- each *entry*, PTE, has a 44-bit physical page number (PPN) and some flags
- so, we use the top 27 bits of the 39 bits to index
	- reserving the bottom 12 bits
	- this creates a 56-bit physical address
- logical view of page table is just an array of PTEs (full story later)
- so the OS gets control over the address translations, at the granularity of aligned chunks of 4096 bytes ($2^{12}$)
	- this is because the bottom 12 bits are unchanged
	- so we have $2^{12}$ options for those while keeping the eventual PPN fixed
- each such chunk is a *page*
- top 25 bits of virtual address not used for translation
- there is room in PTE format for physical page entry to grow by another 10 bits
- $2^{39}$ bytes is 512 GB
	- this should be enough *address space* for applications running on RISC-V computers
	- $2^{56}$ is enough *physical memory space* for lots of I/O devices, RAM chips
	- if more needed, Sv48 defined -- 48-bit virtual addresses
- RISC-V CPU translates virtual --> physical in 3 steps
- *hierarchical* page tables, three-level tree
- the root is a 4096-byte page table page -- the bottom 12 bits of virtual address
	- it has 512 PTEs, so the next 9 bits is the index in the L0
		- these are physical addresses for page-table pages in the next level, L1
	- then, each of *those* L1 pages have 512 PTEs
		- and those PTEs are physical addresses of L2 page tables
- 27 bits -- 9 for L0 page table index, 9 for L1, 9 for L2
- if any of the three required PTEs are not present, **page-fault exception**
	- kernel will handle it
- this is a memory-efficient way of recording PTEs
- in the common case, large ranges of virtual address don't have any mappings
- so then entire page directories can be ommitted
- if only a few pages are used, starting at address zero:
	- then entries 1-511 of top-level page directory are invalid. kernel doesn't have to allocate pages for those, neither mid-level nor bottom-level
	- saves 511 pages for intermediate page directories, and 511 * 512 pages for bottom-level pages
- this three-level structure in hardware is walked by the cpu in hardware
	- as part of a load or store
	- downside of 3 levels? cpu has to load three PTEs from memory
	- so to mitigate this, we also have a [[translation look-aside buffer]] (TLB)
- what's in a page table entry?
	- flag bits telling the paging hardware *how* the virtual address can be used
	- `pte_v` for if it's present; if not set, reference to page causes exception, not allowed
	- `pte_r`: can an instruction read the page?
	- `pte_w`: ^^ but for write
	- `pte_x`: can this be interpreted as instructions and executed?
	- `pte_u`: can user-mode instructions access the page?
		- otherwise, can be used only in supervisor mode
	- etc
- the kernel needs to write physical address of root page-table page into `satp` register
	- the cpu will translate all addresses generated by subsequent instructions using the page table pointed to by its `satp`
	- each cpu has its own `satp`, so different CPUs can run different processes
	- each one has its own private address space, which is described by own page table
- kernel POV: page table is just data stored in memory
	- so the code for creating and modifying these page tables is like code that works with any tree-shaped data structure
- vocab:
	- *physical memory*: storage cells in RAM
	- *physical address*: points to a byte of physical memory
	- instructions that dereference addresses (loads, stores, jumps, function calls) just use virtual addresses
	- the hardware will translate these to physical addresses
	- these are then sent to RAM hardware
	- *address space*: set of virtual addresses valid in given page table
	- each xv6 process has separate user address space
	- xv6 kernel has own address space as well
	- *user memory*: a process's user address space
	- + the physical memory that they're allowed to access (by the page table)
	- *virtual memory*: ideas, techniques associated with page tables. using them to achieve goals, like isolation
# kernel address space
- one page table per process, that describes process's user address space
- a single page table for kernel's address space
- kernel config's layout of address space to give itself access to physical mem and various hardware resources, at predictable virtual addresses
- qemu simulates computer with RAM starting at physical address `0x80000000` and continuing through at least `0x88000000`, called `PHYSTOP`
	- also includes I/O devices like a disk interface
	- qemu exposes device interfaces to software as memory-mapped control regs that sit below `0x80000000` in physical address space
	- kernel can interact with devices by reading/writing special physical addresses
- kernel uses ram and mmapped device registers using direct mapping
	- mapping resources at virtual addresses equal to physical one
- some kernel virtual addresses aren't direct mapped
	- trampoline page, at top of virtual address space
		- user page tables have same mapping
		- physical page is mapped twice in virtual address space of kernel
		- once at top of VA space, once with direct mapping
	- kernel stack pages
		- each process has its own kernel stack, mapped high so below xv6 can leave unmapped guard page
		- if kernel overflows stack, cause exception
		- without guard page, overflowing stack overwrites other kernel memory
# creating an address space
- central data structure is `pagetable_t`
	- pointer to RISC-V root page-table page
	- might be either kernel page table, or per-process one
- functions:
	- `walk`, PTE for virtual address
	- `mappages`, installing PTEs for new mappings
- boot sequence
	- `kvmmake` allocates page of physical memory for root page-table page
	- then `kvmmap` to install translations that kernel needs
		- instructions and data, physical mem up to `PHYSTOP`, mem ranges that are devices
- `proc_mapstacks` allocates kernel stack for each process
- call `kvmmap` to map each stack at virtual address gen. by `KSTACK`, leaving room for guard pages
- `kvmmap` calls `mappages`, installing mappings into page table for range of virtual addresses to range of physical addresses
	- done for each virtual address in range, at page intervals
	- call `walk` to find address of PTE
	- then init PTE to hold relevant PPN, desired permissions, PTE_V
- physical memory direct-mapped into kernel virtual address space
- `main` calls `kvminithart` to install kernel page table
	- write address of root page-table page into `satp` register
- afterwards, translate using kernel page table
- page table entries cached in TLB
	- when page table changed, tell CPU to invalidate cached TLD entries
	- xv6 executes `sfence.vma` to flush TLB
	- done after reloading `satp`
	- and in trampoline code that switches to user page table before returning to user space
- need to do `sfence.vma` before changing `satp`, to wait for outstanding loads and stores to complete, so they use the old page table
# physical memory allocation
- kernel must allocate and free physical mem. at run-time for page tables, user memory, kernel stack, pipe buffers
- physical mem between end of kernel and `PHYSTOP` for runtime alloc
- alloc and free 4096-byte pages at a time
- linked list threaded through pages
# physical memory allocator
- `kalloc.c`
- data structure: free list of physical memory pages that are available
- each free page's list element is a struct run
- how does allocator get memory to hold that?
	- store each free page's run structure in the free page itself
- protected by spin lock
- wrapped in struct, make it clear that lock protects fields
- `main` calls `kinit` to initialize allocator
	- this init's free list to hold every page between end of kernel and `PHYSTOP`
- Should determine how much phys. memory available by parsing config information provided by hardware
- add memory to free list via per-page calls to `kfree`
- PTE can only refer to physical address aligned on 4096-byte boundary
- sometimes treats addresses as integers, in order to perform arithmetic
	- and sometimes uses them as pointers, to read and write memory
	- lots of type casts!
- `kfree` sets all bytes to 1 if freed
	- garbage
- linked list
# process address space
- each process has own page table
- switch page table when switch between processes
- virtual addresses: 0 to `MAXVA`
- address space contains:
	- pages with text of program
		- `PTE_R`, `PTE_X`, `PTE_U`
	- pages containing pre-initialized data of program
	- page for stack
	- pages for heap
		- data is R, W, U flags
- permissions within user address space is common technique to harden user process
	- if mapped with W, then process can modify own program!
	- if try to store at address 0, raise page fault
	- same for `PTE_X` and program execution
- hardening a process by setting perms carefully aids in defending against security attacks
- stack is single page
	- strings containing cmd-line args, as well as array of pointers, are very top of stack
	- under that allow program to start at main, just like if `main(argc, argv)` had just been called
- detection of overflowing stack memory?
	- guard page right below, by clearing `PTE_U` flag
- heap is grown when more user memory needed
- examples of page table use
	- different processes' page tables translate user addresses to different pages of physical memory
	- private memory!
	- each process sees its memory as contiguous starting at 0, but really can be non-contiguous
	- kernel maps page of trampoline code at top of user address space, so a single page of physical memory shows up in all address spaces, but can be used only be kernel!
		- no `PTE_U` flag
# `sbrk`
- syscall for process to shrink or grow memory
- `growproc`, which calls `uvmalloc` or `uvmdealloc`
	- former allocates with `kalloc`, zeros allocated memory, adds PTEs to page table
	- latter `walk`s to find PTEs, and `kfree` to free memory they refer to
- `xv6` uses page table to not just tell hardware how to map user virtual addresses
	- but also as only record of which physical memory pages are allocated
# `exec`
- syscall that replaces process's user address space with data read from file
- open path
- then read ELF header
- ELF binary:
	- ELF header
	- then sequence of program section headers
- `exec` allocates new page table with no user mappings
	- allocates memory for each ELF segment with `uvmalloc`
	- loads each segment into memory with `loadseg`
		- this uses `walkaddr` to find physical address of allocated mem at which to write each page of ELF segment
- alloc, initialize user stack
	- one stack page
	- copies arg strings to top of stack one at a time
- other stuff
# real world
- real OS's use paging and page-fault exceptions